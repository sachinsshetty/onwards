    Building a QA Agent to flag low confidence results

    Deploy an optimizer agent in a loop that improves document performance in the background

    Creating multimodal models for document layout awareness

    Novel chunking strategies for handling long documents

    Building data pipelines and evaluating model performance

    Building a self-correcting system that automatically gets better over time

Role

    Design novel LLM techniques for increasing the complexity of use cases and data streams that Extend can be applied to

    Monitor existing models in production, understand what’s working well (and what isn’t), and run experiments to solve those issues



---

Scale our infrastructure 100x across API calls, document processing workloads, and terabytes of data.

Build deployment pipelines and tooling that let enterprises run Extend in their own environments with one-click deploys

Obsess over performance, and shave milliseconds off latency at every part of our stack.

Create dashboards and alerts that help us understand not just what broke, but why it broke and how to prevent it

Design isolation and security boundaries that let us serve everyone from startups to Fortune 500s on the same platform


---

    How do we enable enterprises to gain confidence in deploying AI?

    How do we handle never before seen edge cases in customer data?

    How do we enable non-technical domain experts to train models with their expertise & business logic?

    How do we enable customers to become experts at prompt engineering?

    How do we help customers understand tradeoffs between latency, cost, and performance, and make the best decision for their use case?

Role

    Write the playbook for how we should work with customers, and how we should incorporate feedback and learnings across the team.

    Build genuine relationships with our end users. You should be on a first-name basis over iMessage, and you’ll have the ability to travel onsite as needed.

    Companies have a lot of unstructured data — you’ll need to figure out what problems other teams are experiencing, and naturally grow dwani.ai within an organization.


--

Training and deploying SOTA vision models for document processing

Design novel LLM techniques for increasing the complexity of use cases and data streams that Extend can be applied to

Monitor existing models in production, understand what’s working well (and what isn’t), and run experiments to solve those issues


--

    How do we build the most accurate document ingestion system?

    How do we enable enterprises to deploy LLM-powered document processing into production with confidence?

    How do we handle never before seen edge cases in customer data?

    How do we build a self-correcting system that automatically gets better over time?

    How do we enable non-technical domain experts to improve models with their expertise & business logic?

    How do we help customers make tradeoffs between latency, cost, and performance?

    How do we build reliable systems that can process large data streams in real-time?

Role

    Build, and maintain, durable, scalable systems capable of processing 10s of millions of data points per month.

    Design and implement the best human ↔ AI interfaces for designing and understanding document processing. We are building a new territory of UX that previously did not exist. It’s up to us to discover and implement new patterns that work for our users.

---

