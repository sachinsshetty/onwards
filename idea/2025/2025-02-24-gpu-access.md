GPU Access

V1

I have integrated models to work with Voice model for Kannada,
It is currently running on a GTX 1060 6GB vram laptop.

Alexa/Siri/Google have a walled garden on Consumer voice product's,
Recently OpenAI's voice mode is an new and strong entrant to the field.

Support is missing for Indian languages,
With open source LLM and models released by AI4BHARAT, we can build similar solutions and make it accessible.

ASR - https://github.com/slabstech/asr-indic-server
TTS - https://github.com/slabstech/parler-tts-server
Translate - https://github.com/slabstech/indic-translate-server

Would you be interested in providing GPU access for 3 months, to make the solution robust.


V2


I plan to use cloud providers for 1 month,
Based on demand or use-case :
On premise can be explored, but upfront investment would be high.


My plan is to execute month by month, to maximize resources and not take extra investment.
---

Napkin math :
3 months total : 120 + 720 + 960 : 1800 dollars.


RTX 4090 24 GB VRAM cost : .5 dollar per hour

Month 1 : Development and optimization- 1-5 user

8 hours run for GPU - 1 GPU

.5 × 8 x 30 = 120 dollars


Month 2 : Scalability tests and beta users : 10-20 users,

16 hours run for GPU - 3 GPU

1.5 × 16 x 30 = 720 dollars


Month 3 : large scale testing across timezones :
10-20 user / Sizing to be done after month 1.

24 hours for GPU : 3 GPU

1.5 × 24 x 30 : 960 dollars
